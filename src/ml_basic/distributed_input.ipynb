{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:51:03.817814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:03.841883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:03.842176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# Simulate multiple CPUs with virtual devices\n",
    "N_VIRTUAL_DEVICES = 2\n",
    "physical_devices = tf.config.list_physical_devices(\"CPU\")\n",
    "tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0], [tf.config.LogicalDeviceConfiguration() for _ in range(N_VIRTUAL_DEVICES)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "0) LogicalDevice(name='/device:CPU:0', device_type='CPU')\n",
      "1) LogicalDevice(name='/device:CPU:1', device_type='CPU')\n",
      "2) LogicalDevice(name='/device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:51:11.928449: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-26 15:51:11.929650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:11.929999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:11.930270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:12.292448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:12.292738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:12.292749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:51:12.292955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:51:12.292995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Available devices:\")\n",
    "for i, device in enumerate(tf.config.list_logical_devices()):\n",
    "  print(\"%d) %s\" % (i, device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "# Create a tf.data.Dataset object.\n",
    "dataset = tf.data.Dataset.from_tensors(\n",
    "    ([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "  features, labels = inputs\n",
    "  return labels - 0.3 * features\n",
    "\n",
    "\n",
    "# Iterate over the dataset using the for..in construct.\n",
    "for inputs in dataset:\n",
    "  print(train_step(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "(<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:51:40.699008: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_2\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(\n",
    "    ([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "# Distribute input using the `experimental_distribute_dataset`.\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "# 1 global batch of data fed to the model in 1 step.\n",
    "print(next(iter(dist_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "dataset = dataset.with_options(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "def dataset_fn(input_context):\n",
    "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
    "  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
    "  dataset = dataset.shard(\n",
    "      input_context.num_input_pipelines, input_context.input_pipeline_id)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(2)  # This prefetches 2 batches per device.\n",
    "  return dataset\n",
    "\n",
    "\n",
    "dist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:52:24.996338: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_2\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:29\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(\n",
    "    ([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "  features, labels = inputs\n",
    "  return labels - 0.3 * features\n",
    "\n",
    "\n",
    "for x in dist_dataset:\n",
    "  # train_step trains the model using the dataset elements\n",
    "  loss = mirrored_strategy.run(train_step, args=(x,))\n",
    "  print(\"Loss is \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "steps_per_epoch = 5\n",
    "for epoch in range(num_epochs):\n",
    "  dist_iterator = iter(dist_dataset)\n",
    "  for step in range(steps_per_epoch):\n",
    "    # train_step trains the model using the dataset elements\n",
    "    loss = mirrored_strategy.run(train_step, args=(next(dist_iterator),))\n",
    "    # which is the same as\n",
    "    # loss = mirrored_strategy.run(train_step, args=(dist_iterator.get_next(),))\n",
    "    print(\"Loss is \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_fn(iterator):\n",
    "  for _ in tf.range(steps_per_loop):\n",
    "    strategy.run(step_fn, args=(next(iterator),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:52:50.929467: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020RangeDataset:104\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0 1 2 3],)\n",
      "([4 5 6 7],)\n",
      "([8],)\n"
     ]
    }
   ],
   "source": [
    "# You can break the loop with `get_next_as_optional` by checking if the `Optional` contains a value\n",
    "global_batch_size = 4\n",
    "steps_per_loop = 5\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.range(9).batch(global_batch_size)\n",
    "distributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_fn(distributed_iterator):\n",
    "  for _ in tf.range(steps_per_loop):\n",
    "    optional_data = distributed_iterator.get_next_as_optional()\n",
    "    if not optional_data.has_value():\n",
    "      break\n",
    "    per_replica_results = strategy.run(\n",
    "        lambda x: x, args=(optional_data.get_value(),))\n",
    "    tf.print(strategy.experimental_local_results(per_replica_results))\n",
    "\n",
    "\n",
    "train_fn(distributed_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:53:02.669828: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_2\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:118\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "epochs = 5\n",
    "steps_per_epoch = 5\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(\n",
    "    ([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[dist_dataset.element_spec])\n",
    "def train_step(per_replica_inputs):\n",
    "  def step_fn(inputs):\n",
    "    return 2 * inputs\n",
    "\n",
    "  return mirrored_strategy.run(step_fn, args=(per_replica_inputs,))\n",
    "\n",
    "\n",
    "for _ in range(epochs):\n",
    "  iterator = iter(dist_dataset)\n",
    "  for _ in range(steps_per_epoch):\n",
    "    output = train_step(next(iterator))\n",
    "    tf.print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FILE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18368/2374805600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Create the layer(s) under scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   integer_preprocessing_layer = tf.keras.layers.IntegerLookup(\n\u001b[0;32m----> 5\u001b[0;31m       vocabulary=FILE_PATH)\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FILE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "  # Create the layer(s) under scope.\n",
    "  integer_preprocessing_layer = tf.keras.layers.IntegerLookup(\n",
    "      vocabulary=FILE_PATH)\n",
    "  model = ...\n",
    "  model.compile(...)\n",
    "dataset = dataset.map(lambda x, y: (integer_preprocessing_layer(x), y))\n",
    "model.fit(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19a8791bd0f1d7536fb3b3f27037595bae98d43b154a4a1d5b777932d4ee9726"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import portpicker\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:36.021073: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-26 15:47:36.079179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.121087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.121451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.500713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.500998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.501009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.501226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.501270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:worker/replica:0/task:0/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.508681: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.508707: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.509739: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:20447\n",
      "2022-03-26 15:47:36.513299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.513608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.513778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.514123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.514138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.514332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.514356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:worker/replica:0/task:1/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.532338: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.532365: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.532732: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:21839\n",
      "2022-03-26 15:47:36.533848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.534148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.534326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.534670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.534684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.534908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.534936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:worker/replica:0/task:2/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.559450: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.559470: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.559757: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:16457\n",
      "2022-03-26 15:47:36.560782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.561040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.561208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.561502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.561513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.561674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.561711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:ps/replica:0/task:0/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.571176: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.571201: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.572598: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:22929\n",
      "2022-03-26 15:47:36.573343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.573601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.573782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.574120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.574136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.574320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.574352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:ps/replica:0/task:1/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.598395: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.598418: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.598850: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:18536\n"
     ]
    }
   ],
   "source": [
    "def create_in_process_cluster(num_workers: int, num_ps: int):\n",
    "    \"\"\"\n",
    "    Create and start local servers and return the cluster_resolver.\n",
    "    \"\"\"\n",
    "    worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]\n",
    "    ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]\n",
    "\n",
    "    cluster_dict = {}\n",
    "    cluster_dict[\"worker\"] = [f\"localhost:{port}\" for port in worker_ports ]\n",
    "    if num_ps > 0:\n",
    "        cluster_dict[\"ps\"] = [f\"localhost:{port}\" for port in ps_ports]\n",
    "    \n",
    "    cluster_spec = tf.train.ClusterSpec(cluster_dict)\n",
    "\n",
    "    # workers need some inter_ops threads to work properly\n",
    "    worker_config = tf.compat.v1.ConfigProto()\n",
    "    if multiprocessing.cpu_count() < num_workers + 1:\n",
    "        worker_config.inter_op_parallelism_threads = num_workers + 1\n",
    "    \n",
    "    for i in range(num_workers):\n",
    "        tf.distribute.Server(\n",
    "            cluster_spec,\n",
    "            job_name=\"worker\",\n",
    "            task_index=i,\n",
    "            protocol='grpc'\n",
    "        )\n",
    "\n",
    "    for i in range(num_ps):\n",
    "        tf.distribute.Server(\n",
    "            cluster_spec,\n",
    "            job_name=\"ps\",\n",
    "            task_index=i,\n",
    "            protocol='grpc'\n",
    "        )\n",
    "    \n",
    "    cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(\n",
    "        cluster_spec=cluster_spec,\n",
    "        rpc_layer='grpc'\n",
    "    )\n",
    "    return cluster_resolver\n",
    "\n",
    "\n",
    "# Set the environment variable to allow reporting worker and ps failure to the\n",
    "# coordinator. This is a workaround and won't be necessary in the future.\n",
    "os.environ[\"GRPC_FAIL_FAST\"] = \"use_caller\"\n",
    "\n",
    "NUM_WORKERS = 3\n",
    "NUM_PS = 2\n",
    "cluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:`tf.distribute.experimental.ParameterServerStrategy` is initialized with cluster_spec: ClusterSpec({'ps': ['localhost:22929', 'localhost:18536'], 'worker': ['localhost:20447', 'localhost:21839', 'localhost:16457']})\n",
      "INFO:tensorflow:ParameterServerStrategyV2 is now connecting to cluster with cluster_spec: ClusterSpec({'ps': ['localhost:22929', 'localhost:18536'], 'worker': ['localhost:20447', 'localhost:21839', 'localhost:16457']})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:36.684220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:chief/replica:0/task:0/device:GPU:0'], variable_device = '/job:chief/replica:0/task:0/device:GPU:0'\n",
      "INFO:tensorflow:Number of GPUs on workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:36.684480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.684665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.685376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.685550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.685749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.686020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.686032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.686176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.686199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.687387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.687536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.687674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.687897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.687907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-26 15:47:36.688046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 15:47:36.688064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:chief/replica:0/task:0/device:GPU:0 with 7403 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-26 15:47:36.691873: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.691886: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.691891: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.746785: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.746827: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.746865: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.746873: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.746899: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.746916: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.746941: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.746954: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.746958: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.746961: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.746976: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.746989: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:279] Creating sync eager service context with rendezvous_id on host lisy09-win /job:ps/replica:0/task:0\n",
      "2022-03-26 15:47:36.747002: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:279] Creating sync eager service context with rendezvous_id on host lisy09-win /job:ps/replica:0/task:1\n",
      "2022-03-26 15:47:36.747019: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:279] Creating sync eager service context with rendezvous_id on host lisy09-win /job:worker/replica:0/task:1\n",
      "2022-03-26 15:47:36.747070: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.747081: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.747093: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.747097: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.748451: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:279] Creating sync eager service context with rendezvous_id on host lisy09-win /job:worker/replica:0/task:2\n",
      "2022-03-26 15:47:36.749671: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:279] Creating sync eager service context with rendezvous_id on host lisy09-win /job:worker/replica:0/task:0\n",
      "2022-03-26 15:47:36.754721: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job ps -> {0 -> localhost:22929, 1 -> localhost:18536}\n",
      "2022-03-26 15:47:36.754735: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20447, 1 -> localhost:21839, 2 -> localhost:16457}\n",
      "2022-03-26 15:47:36.754740: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job chief -> {0 -> localhost:49943}\n",
      "2022-03-26 15:47:36.755016: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:49943\n"
     ]
    }
   ],
   "source": [
    "variable_partitioner = (\n",
    "    tf.distribute.experimental.partitioners.MinSizePartitioner(\n",
    "        min_shard_bytes=(256<<10),\n",
    "        max_shards=NUM_PS\n",
    "    )\n",
    ")\n",
    "strategy = tf.distribute.experimental.ParameterServerStrategy(\n",
    "    cluster_resolver,\n",
    "    variable_partitioner=variable_partitioner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_fn(input_context):\n",
    "  global_batch_size = 64\n",
    "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
    "\n",
    "  x = tf.random.uniform((10, 10))\n",
    "  y = tf.random.uniform((10,))\n",
    "\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(10).repeat()\n",
    "  dataset = dataset.shard(\n",
    "      input_context.num_input_pipelines,\n",
    "      input_context.input_pipeline_id)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(2)\n",
    "\n",
    "  return dataset\n",
    "\n",
    "\n",
    "dc = tf.keras.utils.experimental.DatasetCreator(dataset_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
    "\n",
    "  model.compile(tf.keras.optimizers.SGD(), loss='mse', steps_per_execution=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:39.649413: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-03-26 15:47:39.825247: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/my_working_dir/ckpt/assets\n",
      "20/20 - 3s - loss: 0.4427 - 3s/epoch - 131ms/step\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:39.993883: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n",
      "2022-03-26 15:47:40.054713: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/my_working_dir/ckpt/assets\n",
      "20/20 - 1s - loss: 0.2545 - 527ms/epoch - 26ms/step\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:40.529958: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n",
      "2022-03-26 15:47:40.584764: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7fb664093550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: /tmp/my_working_dir/ckpt/assets\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7fb6643909d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "20/20 - 0s - loss: 0.3399 - 334ms/epoch - 17ms/step\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:40.869063: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n",
      "2022-03-26 15:47:40.924010: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/my_working_dir/ckpt/assets\n",
      "20/20 - 0s - loss: 0.3189 - 336ms/epoch - 17ms/step\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:41.209372: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n",
      "2022-03-26 15:47:41.263835: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/my_working_dir/ckpt/assets\n",
      "20/20 - 0s - loss: 0.1785 - 331ms/epoch - 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 15:47:41.547049: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n",
      "2022-03-26 15:47:41.599771: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:94] Ignoring error status when releasing multi-device function handle UNIMPLEMENTED: Releasing a multi-device component handle on a remote device is not yet implemented.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb68888db50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = '/tmp/my_working_dir'\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "ckpt_filepath = os.path.join(working_dir, 'ckpt')\n",
    "backup_dir = os.path.join(working_dir, 'backup')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath),\n",
    "    tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir),\n",
    "]\n",
    "\n",
    "model.fit(dc, epochs=5, steps_per_epoch=20, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisy09/develop/repo/research-to-applied-ml/venv/lib/python3.8/site-packages/numpy/core/numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "feature_vocab = [\n",
    "    \"avenger\", \"ironman\", \"batman\", \"hulk\", \"spiderman\", \"kingkong\", \"wonder_woman\"\n",
    "]\n",
    "label_vocab = [\"yes\", \"no\"]\n",
    "\n",
    "with strategy.scope():\n",
    "  feature_lookup_layer = tf.keras.layers.StringLookup(\n",
    "      vocabulary=feature_vocab,\n",
    "      mask_token=None)\n",
    "  label_lookup_layer = tf.keras.layers.StringLookup(\n",
    "      vocabulary=label_vocab,\n",
    "      num_oov_indices=0,\n",
    "      mask_token=None)\n",
    "\n",
    "  raw_feature_input = tf.keras.layers.Input(\n",
    "      shape=(3,),\n",
    "      dtype=tf.string,\n",
    "      name=\"feature\")\n",
    "  feature_id_input = feature_lookup_layer(raw_feature_input)\n",
    "  feature_preprocess_stage = tf.keras.Model(\n",
    "      {\"features\": raw_feature_input},\n",
    "      feature_id_input)\n",
    "\n",
    "  raw_label_input = tf.keras.layers.Input(\n",
    "      shape=(1,),\n",
    "      dtype=tf.string,\n",
    "      name=\"label\")\n",
    "  label_id_input = label_lookup_layer(raw_label_input)\n",
    "\n",
    "  label_preprocess_stage = tf.keras.Model(\n",
    "      {\"label\": raw_label_input},\n",
    "      label_id_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def feature_and_label_gen(num_examples=200):\n",
    "  examples = {\"features\": [], \"label\": []}\n",
    "  for _ in range(num_examples):\n",
    "    features = random.sample(feature_vocab, 3)\n",
    "    label = [\"yes\"] if \"avenger\" in features else [\"no\"]\n",
    "    examples[\"features\"].append(features)\n",
    "    examples[\"label\"].append(label)\n",
    "  return examples\n",
    "\n",
    "\n",
    "examples = feature_and_label_gen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_fn(_):\n",
    "  raw_dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
    "\n",
    "  train_dataset = raw_dataset.map(\n",
    "      lambda x: (\n",
    "          {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
    "          label_preprocess_stage(x[\"label\"])\n",
    "      )).shuffle(200).batch(32).repeat()\n",
    "  return train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables created under the `Strategy.scope` will be placed on parameter\n",
    "# servers in a round-robin fashion.\n",
    "with strategy.scope():\n",
    "  # Create the model. The input needs to be compatible with Keras processing layers.\n",
    "  model_input = tf.keras.layers.Input(\n",
    "      shape=(3,), dtype=tf.int64, name=\"model_input\")\n",
    "\n",
    "  emb_layer = tf.keras.layers.Embedding(\n",
    "      input_dim=len(feature_lookup_layer.get_vocabulary()), output_dim=16384)\n",
    "  emb_output = tf.reduce_mean(emb_layer(model_input), axis=1)\n",
    "  dense_output = tf.keras.layers.Dense(\n",
    "      units=1, activation=\"sigmoid\")(emb_output)\n",
    "  model = tf.keras.Model({\"features\": model_input}, dense_output)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
    "  accuracy = tf.keras.metrics.Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(emb_layer.weights) == 2\n",
    "assert emb_layer.weights[0].shape == (4, 16384)\n",
    "assert emb_layer.weights[1].shape == (4, 16384)\n",
    "assert emb_layer.weights[0].device == \"/job:ps/replica:0/task:0/device:CPU:0\"\n",
    "assert emb_layer.weights[1].device == \"/job:ps/replica:0/task:1/device:CPU:0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def step_fn(iterator):\n",
    "\n",
    "  def replica_fn(batch_data, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      pred = model(batch_data, training=True)\n",
    "      per_example_loss = tf.keras.losses.BinaryCrossentropy(\n",
    "          reduction=tf.keras.losses.Reduction.NONE)(labels, pred)\n",
    "      loss = tf.nn.compute_average_loss(per_example_loss)\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
    "    accuracy.update_state(labels, actual_pred)\n",
    "    return loss\n",
    "\n",
    "  batch_data, labels = next(iterator)\n",
    "  losses = strategy.run(replica_fn, args=(batch_data, labels))\n",
    "  return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(\n",
    "    strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.string, name='feature'), name='feature', description=\"created by layer 'feature'\"), but it was called on an input with incompatible shape (3,).\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def per_worker_dataset_fn():\n",
    "  return strategy.distribute_datasets_from_function(dataset_fn)\n",
    "\n",
    "\n",
    "per_worker_dataset = coordinator.create_per_worker_dataset(\n",
    "    per_worker_dataset_fn)\n",
    "per_worker_iterator = iter(per_worker_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/device:CPU:0',).\n",
      "Finished epoch 0, accuracy is 0.675000.\n",
      "Finished epoch 1, accuracy is 0.500000.\n",
      "Finished epoch 2, accuracy is 0.781250.\n",
      "Finished epoch 3, accuracy is 1.000000.\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 4\n",
    "steps_per_epoch = 5\n",
    "for i in range(num_epoches):\n",
    "  accuracy.reset_states()\n",
    "  for _ in range(steps_per_epoch):\n",
    "    coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
    "  # Wait at epoch boundaries.\n",
    "  coordinator.join()\n",
    "  print(\"Finished epoch %d, accuracy is %f.\" % (i, accuracy.result().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is 0.000000\n"
     ]
    }
   ],
   "source": [
    "loss = coordinator.schedule(step_fn, args=(per_worker_iterator,))\n",
    "print(\"Final loss is %f\" % loss.fetch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.string, name='feature'), name='feature', description=\"created by layer 'feature'\"), but it was called on an input with incompatible shape (3,).\n",
      "Evaluation accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    feature_and_label_gen(num_examples=16)).map(\n",
    "    lambda x: (\n",
    "        {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
    "        label_preprocess_stage(x[\"label\"])\n",
    "    )).batch(8)\n",
    "\n",
    "eval_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for batch_data, labels in eval_dataset:\n",
    "  pred = model(batch_data, training=False)\n",
    "  actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
    "  eval_accuracy.update_state(labels, actual_pred)\n",
    "\n",
    "print(\"Evaluation accuracy: %f\" % eval_accuracy.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.string, name='feature'), name='feature', description=\"created by layer 'feature'\"), but it was called on an input with incompatible shape (3,).\n",
      "WARNING:tensorflow:1 GPUs are allocated per worker. Please use DistributedDataset by calling strategy.experimental_distribute_dataset or strategy.distribute_datasets_from_function to make best use of GPU resources\n",
      "WARNING:tensorflow:1 GPUs are allocated per worker. Please use DistributedDataset by calling strategy.experimental_distribute_dataset or strategy.distribute_datasets_from_function to make best use of GPU resources\n",
      "WARNING:tensorflow:1 GPUs are allocated per worker. Please use DistributedDataset by calling strategy.experimental_distribute_dataset or strategy.distribute_datasets_from_function to make best use of GPU resources\n",
      "Evaluation accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  # Define the eval metric on parameter servers.\n",
    "  eval_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def eval_step(iterator):\n",
    "  def replica_fn(batch_data, labels):\n",
    "    pred = model(batch_data, training=False)\n",
    "    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)\n",
    "    eval_accuracy.update_state(labels, actual_pred)\n",
    "  batch_data, labels = next(iterator)\n",
    "  strategy.run(replica_fn, args=(batch_data, labels))\n",
    "\n",
    "\n",
    "def eval_dataset_fn():\n",
    "  return tf.data.Dataset.from_tensor_slices(\n",
    "      feature_and_label_gen(num_examples=16)).map(\n",
    "          lambda x: (\n",
    "              {\"features\": feature_preprocess_stage(x[\"features\"])},\n",
    "              label_preprocess_stage(x[\"label\"])\n",
    "          )).shuffle(16).repeat().batch(8)\n",
    "\n",
    "\n",
    "per_worker_eval_dataset = coordinator.create_per_worker_dataset(\n",
    "    eval_dataset_fn)\n",
    "per_worker_eval_iterator = iter(per_worker_eval_dataset)\n",
    "\n",
    "eval_steps_per_epoch = 2\n",
    "for _ in range(eval_steps_per_epoch):\n",
    "  coordinator.schedule(eval_step, args=(per_worker_eval_iterator,))\n",
    "coordinator.join()\n",
    "print(\"Evaluation accuracy: %f\" % eval_accuracy.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19a8791bd0f1d7536fb3b3f27037595bae98d43b154a4a1d5b777932d4ee9726"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
